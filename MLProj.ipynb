{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0781af2-0fe6-444b-a827-8ae587ec03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "import sacrebleu\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f0112f-688e-40e4-a150-96e220c223a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Tagalog Sentence  \\\n",
      "0                        Siya ay nagbabasa.   \n",
      "1                        Sila ay nagbabasa.   \n",
      "2  Si Maria ay nagluluto. Siya ay kumakain.   \n",
      "3       Si Juan ay tumatakbo. Siya ay uhaw.   \n",
      "4                       Siya ay nagkakamot.   \n",
      "\n",
      "                                     Tagged Sentence  \\\n",
      "0  Siya [singular, third-person, gender-neutral] ...   \n",
      "1          Sila [plural, third-person] ay nagbabasa.   \n",
      "2  Si Maria ay nagluluto. Siya [singular, third-p...   \n",
      "3  Si Juan ay tumatakbo. Siya [singular, third-pe...   \n",
      "4  Siya [singular, third-person, gender-neutral] ...   \n",
      "\n",
      "                English Translation  \\\n",
      "0                 They are reading.   \n",
      "1                 They are reading.   \n",
      "2  Maria is cooking. She is eating.   \n",
      "3   Juan is running. He is thirsty.   \n",
      "4                 They are itching.   \n",
      "\n",
      "                           Pronoun Annotation  \n",
      "0  Pronoun = \"they,\" singular, gender-neutral  \n",
      "1                    Pronoun = \"they,\" plural  \n",
      "2  Pronoun = \"she,\" singular, gender-specific  \n",
      "3   Pronoun = \"he,\" singular, gender-specific  \n",
      "4  Pronoun = \"they,\" singular, gender-neutral  \n"
     ]
    }
   ],
   "source": [
    "#loading the data set\n",
    "df = pd.read_csv('train1.csv')\n",
    "print(df.head())\n",
    "\n",
    "#use 'Tagged Sentence' for training input and 'English Translation' as the target otherwise replace Tagged Sentence with Tagalog if you want to train it without the tagged pronouns or uncomment the line below\n",
    "#tagalog_sentences = df['Tagalog']\n",
    "\n",
    "tagalog_sentences = df['Tagged Sentence']\n",
    "english_translations = df['English Translation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fb59394-338b-43c2-bb29-77fa723d93a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mvich\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#loading BART tokenizer and tokenizing inputs(tagalog_sentences) and targets (english_translations)\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "inputs = tokenizer(list(tagalog_sentences), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "targets = tokenizer(list(english_translations), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "\n",
    "#checking the tokenized input and target examples:\n",
    "#print(inputs['input_ids'][0])\n",
    "#print(targets['input_ids'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ec1340-b9c7-46ee-819a-6a6549bf7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data are split into training and validation sets (80% train, 20% for validation)\n",
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(inputs['input_ids'], targets['input_ids'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76df12c3-ccb5-4880-a273-b05c8eb53d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating datasets and dataloaders from inputs and targets \n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "val_dataset = TensorDataset(val_inputs, val_targets)\n",
    "#dataloaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "279e9e77-0298-4eac-9d91-32f10d61101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(i always get an error if i set cuda alone that's why i made this if else cpu)\n",
    "#if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')  #GPU is available, use it\n",
    "else:\n",
    "    device = torch.device('cpu')  #GPU not available, use CPU\n",
    "\n",
    "#load pre-trained BART model\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "#defining optimizer Adamw\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01531455-3a66-428d-9ad9-a24cdc05a06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Training Loss: 4.787105048289065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9432356879115105\n",
      "Epoch 2/3, Training Loss: 1.1138243577519402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.741957537829876\n",
      "Epoch 3/3, Training Loss: 0.698284062205768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7312694564461708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bart\\\\tokenizer_config.json',\n",
       " './fine_tuned_bart\\\\special_tokens_map.json',\n",
       " './fine_tuned_bart\\\\vocab.json',\n",
       " './fine_tuned_bart\\\\merges.txt',\n",
       " './fine_tuned_bart\\\\added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "#can increase more epochs if needed\n",
    "epochs = 3\n",
    "best_val_loss = float('inf')\n",
    "patience = 3 \n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, target_ids = [b.to(device) for b in batch]\n",
    "        outputs = model(input_ids=input_ids, labels=target_ids)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "    #validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids, target_ids = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, labels=target_ids)\n",
    "            val_loss += outputs.loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "\n",
    "    #early stopping to prevent overfitting by the model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        model.save_pretrained('./best_fine_tuned_bart')  \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "    #if model reaches the patience threshold without improvement, stop training\n",
    "            print(\"Early stopping initiated!\")\n",
    "            break\n",
    "\n",
    "#saving the final model after training\n",
    "model.save_pretrained('./fine_tuned_bart')  \n",
    "tokenizer.save_pretrained('./fine_tuned_bart') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19f671c2-46d1-4718-9ae3-bed6acc49e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 75.98356856515926\n",
      "Precision: 0.0629\n",
      "Recall: 0.0630\n",
      "F1 Score: 0.0620\n",
      "Accuracy: 0.0630\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "def evaluate_metrics(model, val_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    #tokenized references for word-level comparisons\n",
    "    tokenized_references = []\n",
    "    #tokenized predictions for word-level comparisons\n",
    "    tokenized_predictions = []  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids, target_ids = [b.to(device) for b in batch]\n",
    "            #can choose to have different num_beams, i have tried wih 7, 10 but kept it at 5.\n",
    "            generated_ids = model.generate(input_ids=input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
    "            decoded_preds = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n",
    "            decoded_refs = [tokenizer.decode(t, skip_special_tokens=True) for t in target_ids]\n",
    "            \n",
    "            predictions.extend(decoded_preds)\n",
    "            references.extend(decoded_refs)\n",
    "            \n",
    "            #tokenizing for word-level metrics\n",
    "            for ref in decoded_refs:\n",
    "                tokenized_references.append(ref.split())\n",
    "            for pred in decoded_preds:\n",
    "                tokenized_predictions.append(pred.split())\n",
    "    \n",
    "    #calculate BLEU score (for discussion purposes)\n",
    "    bleu = sacrebleu.corpus_bleu(predictions, [[r] for r in references])\n",
    "    print(f\"BLEU Score: {bleu.score}\")\n",
    "\n",
    "    #the tokenized references are lists of words and I decided to flatten them into a single list\n",
    "    #for word-level comparisons (forevaluation of precision, recall, F1 score, accuracy)\n",
    "    #flatten tokenized_references and tokenized_predictions for word-level evaluation\n",
    "    flat_references = []\n",
    "    flat_predictions = []\n",
    "    \n",
    "    #flatten tokenized_references into flat_references\n",
    "    for ref in tokenized_references:\n",
    "        for word in ref:\n",
    "            flat_references.append(word)\n",
    "\n",
    "    #flatten tokenized_predictions into flat_predictions\n",
    "    #similar to references, tokenized predictions need to be flattened for individual word comparisons\n",
    "    for pred in tokenized_predictions:\n",
    "        for word in pred:\n",
    "            flat_predictions.append(word)\n",
    "    \n",
    "    #making sure flat_references and flat_predictions have equal lengths\n",
    "    #making sure the accuracy, precision, recall and F1 scores are calculated correctly\n",
    "    #this concerns whether the two lists have different lengths then they cannot be directly compared for evaluation\n",
    "    min_length = min(len(flat_references), len(flat_predictions))\n",
    "    flat_references = flat_references[:min_length]\n",
    "    flat_predictions = flat_predictions[:min_length]\n",
    "    \n",
    "    #calculating precision, recall, F1, and accuracy\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(flat_references, flat_predictions, average='weighted', zero_division=0)\n",
    "    accuracy = accuracy_score(flat_references, flat_predictions)\n",
    "\n",
    "#overall evaluation scores:\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# Call the evaluation function\n",
    "evaluate_metrics(model, val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43901590-c0d8-41a2-8632-77ea1bb1b54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Siya ay nagluluto.\n",
      "Expected Translation: They(sg) are cooking.\n",
      "Generated Translation: They are buying fruits.\n",
      "Word-Level Accuracy: 25.00%\n",
      "==================================================\n",
      "Original: Sila ay nagtatrabaho.\n",
      "Expected Translation: They(pl) are working.\n",
      "Generated Translation: They are buying fruits.\n",
      "Word-Level Accuracy: 25.00%\n",
      "==================================================\n",
      "Original: Si Maria ay nagsusulat.\n",
      "Expected Translation: Maria is writing.\n",
      "Generated Translation: Maria is cooking a dish. She is good.\n",
      "Word-Level Accuracy: 25.00%\n",
      "==================================================\n",
      "Original: Si Juan ay naglalaro ng basketball.\n",
      "Expected Translation: Juan is playing basketball.\n",
      "Generated Translation: Juan is playing basketball.\n",
      "Word-Level Accuracy: 100.00%\n",
      "==================================================\n",
      "Original: Siya ay natutulog.\n",
      "Expected Translation: They(sg) are sleeping.\n",
      "Generated Translation: They are buying fruits.\n",
      "Word-Level Accuracy: 25.00%\n",
      "==================================================\n",
      "Original: Siya ay nag-aaral ng Ingles.\n",
      "Expected Translation: They(sg) are studying English.\n",
      "Generated Translation: They are studying math.\n",
      "Word-Level Accuracy: 50.00%\n",
      "==================================================\n",
      "Original: Sila ay nagbabasa ng aklat.\n",
      "Expected Translation: They(pl) are reading a book.\n",
      "Generated Translation: They are playing hide and seek.\n",
      "Word-Level Accuracy: 16.67%\n",
      "==================================================\n",
      "Original: Siya ay kumakain ng almusal.\n",
      "Expected Translation: They(sg) are eating breakfast.\n",
      "Generated Translation: They are cooking a dish.\n",
      "Word-Level Accuracy: 20.00%\n",
      "==================================================\n",
      "Original: Si Pedro ay naglilinis ng kotse.\n",
      "Expected Translation: Pedro is cleaning the car.\n",
      "Generated Translation: Pedro is fixing a broken car.\n",
      "Word-Level Accuracy: 33.33%\n",
      "==================================================\n",
      "Original: Nagaaral siya ng hapon.\n",
      "Expected Translation: They(sg) are learning Japanese\n",
      "Generated Translation: They are buying fruits.\n",
      "Word-Level Accuracy: 25.00%\n",
      "==================================================\n",
      "Original: Si Ana ay nagpapatugtog ng piano.\n",
      "Expected Translation: Ana is playing the piano.\n",
      "Generated Translation: Ana is playing the piano.\n",
      "Word-Level Accuracy: 100.00%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#testing example Tagalog sentences with input on the left and expected output on the right (with accuracy calculation)\n",
    "test_sentences = [\n",
    "    (\"Siya ay nagluluto.\", \"They(sg) are cooking.\"),               \n",
    "    (\"Sila ay nagtatrabaho.\", \"They(pl) are working.\"),\n",
    "    (\"Si Maria ay nagsusulat.\", \"Maria is writing.\"),\n",
    "    (\"Si Juan ay naglalaro ng basketball.\", \"Juan is playing basketball.\"),\n",
    "    (\"Siya ay natutulog.\", \"They(sg) are sleeping.\"),\n",
    "    (\"Siya ay nag-aaral ng Ingles.\", \"They(sg) are studying English.\"),\n",
    "    (\"Sila ay nagbabasa ng aklat.\", \"They(pl) are reading a book.\"),\n",
    "    (\"Siya ay kumakain ng almusal.\", \"They(sg) are eating breakfast.\"),\n",
    "    (\"Si Pedro ay naglilinis ng kotse.\", \"Pedro is cleaning the car.\"),\n",
    "    (\"Nagaaral siya ng hapon.\", \"They(sg) are learning Japanese\"),\n",
    "    (\"Si Ana ay nagpapatugtog ng piano.\", \"Ana is playing the piano.\")\n",
    "]\n",
    "\n",
    "for test_sentence, expected_translation in test_sentences:\n",
    "    test_inputs = tokenizer(test_sentence, return_tensors='pt', truncation=True, max_length=128).to(device)\n",
    "\n",
    "    #generating and decoding translation \n",
    "    #can change num_beams\n",
    "    translated_ids = model.generate(test_inputs['input_ids'], max_length=50, num_beams=5, early_stopping=True)\n",
    "    translated_sentence = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    #word-level accuracy calculation\n",
    "    expected_words = expected_translation.split()\n",
    "    translated_words = translated_sentence.split()\n",
    "    correct_words = 0\n",
    "    for ew, tw in zip(expected_words, translated_words):\n",
    "        if ew == tw:\n",
    "            correct_words += 1\n",
    "    accuracy = correct_words / max(len(expected_words), len(translated_words)) * 100  \n",
    "    print(f\"Original: {test_sentence}\")\n",
    "    print(f\"Expected Translation: {expected_translation}\")\n",
    "    print(f\"Generated Translation: {translated_sentence}\")\n",
    "    print(f\"Word-Level Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89fdd084-89f5-458e-b24c-9b97daedc1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Siya ay nagluluto.\n",
      "Expected Translation: They are cooking.\n",
      "Generated Translation: They are buying fruits.\n",
      "Word-Level Accuracy: 50.00%\n",
      "Sentence BLEU Score: 23.64\n",
      "==================================================\n",
      "Original: Sila ay nagtatrabaho.\n",
      "Expected Translation: They are working.\n",
      "Generated Translation: They are buying fruits.\n",
      "Word-Level Accuracy: 50.00%\n",
      "Sentence BLEU Score: 23.64\n",
      "==================================================\n",
      "Original: Si Maria ay nagsusulat.\n",
      "Expected Translation: Maria is writing.\n",
      "Generated Translation: Maria is cooking a dish. She is good.\n",
      "Word-Level Accuracy: 25.00%\n",
      "Sentence BLEU Score: 9.29\n",
      "==================================================\n",
      "Original: Si Juan ay naglalaro ng basketball.\n",
      "Expected Translation: Juan is playing basketball.\n",
      "Generated Translation: Juan is playing basketball.\n",
      "Word-Level Accuracy: 100.00%\n",
      "Sentence BLEU Score: 100.00\n",
      "==================================================\n",
      "Original: Siya ay natutulog.\n",
      "Expected Translation: They are sleeping.\n",
      "Generated Translation: They are buying fruits.\n",
      "Word-Level Accuracy: 50.00%\n",
      "Sentence BLEU Score: 23.64\n",
      "==================================================\n",
      "Original: Siya ay nag-aaral ng Ingles.\n",
      "Expected Translation: They are studying English.\n",
      "Generated Translation: They are studying math.\n",
      "Word-Level Accuracy: 75.00%\n",
      "Sentence BLEU Score: 42.73\n",
      "==================================================\n",
      "Original: Sila ay nagbabasa ng aklat.\n",
      "Expected Translation: They are reading a book.\n",
      "Generated Translation: They are playing hide and seek.\n",
      "Word-Level Accuracy: 33.33%\n",
      "Sentence BLEU Score: 14.54\n",
      "==================================================\n",
      "Original: Siya ay kumakain ng almusal.\n",
      "Expected Translation: They are eating breakfast.\n",
      "Generated Translation: They are cooking a dish.\n",
      "Word-Level Accuracy: 40.00%\n",
      "Sentence BLEU Score: 17.97\n",
      "==================================================\n",
      "Original: Si Pedro ay naglilinis ng kotse.\n",
      "Expected Translation: Pedro is cleaning the car.\n",
      "Generated Translation: Pedro is fixing a broken car.\n",
      "Word-Level Accuracy: 33.33%\n",
      "Sentence BLEU Score: 18.58\n",
      "==================================================\n",
      "Original: Si Ana ay nagpapatugtog ng piano.\n",
      "Expected Translation: Ana is playing the piano.\n",
      "Generated Translation: Ana is playing the piano.\n",
      "Word-Level Accuracy: 100.00%\n",
      "Sentence BLEU Score: 100.00\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#testing example Tagalog sentences with input on the left and expected output on the right (with accuracy and bleu calculation)\n",
    "test_sentences = [\n",
    "    (\"Siya ay nagluluto.\", \"They are cooking.\"),\n",
    "    (\"Sila ay nagtatrabaho.\", \"They are working.\"),\n",
    "    (\"Si Maria ay nagsusulat.\", \"Maria is writing.\"),\n",
    "    (\"Si Juan ay naglalaro ng basketball.\", \"Juan is playing basketball.\"),\n",
    "    (\"Siya ay natutulog.\", \"They are sleeping.\"),\n",
    "    (\"Siya ay nag-aaral ng Ingles.\", \"They are studying English.\"),\n",
    "    (\"Sila ay nagbabasa ng aklat.\", \"They are reading a book.\"),\n",
    "    (\"Siya ay kumakain ng almusal.\", \"They are eating breakfast.\"),\n",
    "    (\"Si Pedro ay naglilinis ng kotse.\", \"Pedro is cleaning the car.\"),\n",
    "    (\"Si Ana ay nagpapatugtog ng piano.\", \"Ana is playing the piano.\")\n",
    "]\n",
    "\n",
    "\n",
    "for test_sentence, expected_translation in test_sentences:\n",
    "    #tokenizing the test sentence\n",
    "    test_inputs = tokenizer(test_sentence, return_tensors='pt', truncation=True, max_length=128).to(device)\n",
    "\n",
    "    #generating and decoding translation \n",
    "    translated_ids = model.generate(test_inputs['input_ids'], max_length=50, num_beams=7, early_stopping=True)\n",
    "    translated_sentence = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    #word-level accuracy\n",
    "    expected_words = expected_translation.split()\n",
    "    translated_words = translated_sentence.split()\n",
    "    correct_words = 0\n",
    "    for ew, tw in zip(expected_words, translated_words):\n",
    "        if ew == tw:\n",
    "            correct_words += 1\n",
    "    accuracy = correct_words / max(len(expected_words), len(translated_words)) * 100  \n",
    "\n",
    "    #BLEU score \n",
    "    bleu = sacrebleu.corpus_bleu([translated_sentence], [[expected_translation]])\n",
    "    print(f\"Original: {test_sentence}\")\n",
    "    print(f\"Expected Translation: {expected_translation}\")\n",
    "    print(f\"Generated Translation: {translated_sentence}\")\n",
    "    print(f\"Word-Level Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Sentence BLEU Score: {bleu.score:.2f}\")\n",
    "    print(\"=\" * 50) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78f6fd-a67b-4e0d-9dd8-fac291886684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
